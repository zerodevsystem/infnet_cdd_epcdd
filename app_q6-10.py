import os
import streamlit as st
import requests
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
from collections import Counter
from dotenv import load_dotenv
import pandas as pd
import numpy as np
from openai import OpenAI

from simpsons_analysis import analyze_episode_summary, test_api_connection, analyze_episode
from summary_metrics import compare_summaries, analyze_convergence
from export import export_sentiment_analysis
from sentiment_visualization import main as sentiment_viz_main
from simpsons_sentiment_analysis import analyze_simpsons_sentiments, test_api_connection, export_to_csv
from sentiment_visualization import main as sentiment_viz_main

st.set_page_config(page_title="Gerador de Texto AI e Categoriza√ß√£o de Manchetes", page_icon="ü§ñ", layout="wide")

load_dotenv()

# vari√°veis de estado
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
if 'episode_lines' not in st.session_state:
    st.session_state.episode_lines = None
if 'distribution' not in st.session_state:
    st.session_state.distribution = None
if 'num_calls' not in st.session_state:
    st.session_state.num_calls = 0

# Configura o cliente nvidia
client = OpenAI(
    base_url=os.getenv("OPENAI_BASE_URL"),
    api_key=os.getenv("OPENAI_API_KEY")
)

def read_project_info():
    try:
        with open('project_info.txt', 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        return "Informa√ß√µes do projeto n√£o encontradas."

# coletar manchetes
def get_headlines():
    url = "https://noticias.ufal.br/"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    headlines = [h.text.strip() for h in soup.find_all('a', class_='titulo')]
    return headlines

def create_chart(categorized):
    categories = [item['category'] for item in categorized]
    count = Counter(categories)
    
    fig, ax = plt.subplots()
    ax.bar(count.keys(), count.values())
    ax.set_title('Categoriza√ß√£o das Manchetes da UFAL')
    ax.set_xlabel('Categorias')
    ax.set_ylabel('Quantidade de Manchetes')
    
    return fig, count

# Fun√ß√£o para a aplica√ß√£o de categoriza√ß√£o de manchetes
def headline_categorization_app():
    st.header("Categoriza√ß√£o de Manchetes da UFAL")
    st.write("A funcionalidade de categoriza√ß√£o est√° temporariamente indispon√≠vel.")
    
    if st.button("Coletar Manchetes"):
        with st.spinner("Coletando manchetes..."):
            headlines = get_headlines()
            st.subheader("Manchetes Coletadas:")
            for headline in headlines:
                st.write(headline)

# T√≠tulo principal da aplica√ß√£o
st.title("ü§ñ Gerador de Texto AI e Categoriza√ß√£o de Manchetes & ü§ñ An√°lise de Texto e Dados")

# Abas principais
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10, tab11 = st.tabs([
    "Apresenta√ß√£o", 
    "Gerador de Texto", 
    "Categoriza√ß√£o de Manchetes", 
    "An√°lise The Simpsons", 
    "An√°lise de Sentimentos Simpsons",
    "Chat com Ollama",
    "Resumo do Epis√≥dio",
    "Resumo Detalhado do Epis√≥dio",
    "Compara√ß√£o de M√©tricas",
    "Exportar An√°lise de Sentimento",
    "Visualiza√ß√£o de Sentimentos"
])

with tab1:
    project_info = read_project_info()
    st.markdown(project_info)

with tab2:
    st.write("Gerador de Texto AI est√° temporariamente indispon√≠vel.")

with tab3:
    headline_categorization_app()

with tab4:
    st.write("An√°lise The Simpsons est√° temporariamente indispon√≠vel.")

# with tab5:
#     st.subheader("An√°lise de Sentimentos dos Simpsons")
    
#     if st.button("Testar Conex√£o com API"):
#         if test_api_connection():
#             st.success("Conex√£o com a API bem-sucedida!")
#         else:
#             st.error("Falha na conex√£o com a API. Verifique os logs para mais detalhes.")
    
#     if st.button("Iniciar An√°lise de Sentimentos"):
#         with st.spinner("Analisando sentimentos dos di√°logos dos Simpsons..."):
#             progress_bar = st.progress(0)
            
#             def update_progress(progress):
#                 progress_bar.progress(progress)
            
#             episode_lines, distribution, accuracy, precision, num_calls = analyze_simpsons_sentiments(update_progress)
            
#             # remove a barra de progresso ap√≥s a conclus√£o
#             progress_bar.empty()
        
#         st.success("An√°lise conclu√≠da!")
#         st.subheader("N√∫mero de chamadas ao LLM")
#         st.write(f"Foram necess√°rias {num_calls} chamadas ao LLM.")
#         st.subheader("Distribui√ß√£o de Sentimentos")
#         fig, ax = plt.subplots()
#         distribution.plot(kind='bar', ax=ax)
#         plt.title("Distribui√ß√£o de Sentimentos nas Falas")
#         plt.xlabel("Sentimento")
#         plt.ylabel("Propor√ß√£o")
#         st.pyplot(fig)

#         st.subheader("Exemplo de Falas Classificadas")
#         if not episode_lines.empty and 'sentiment' in episode_lines.columns:
#             sample = episode_lines[['spoken_words', 'sentiment']].dropna().sample(10, random_state=42)
#             st.dataframe(sample.style.set_properties(**{'text-align': 'left'}))
#         else:
#             st.write("N√£o h√° dados de sentimento dispon√≠veis.")


with tab5:
    st.subheader("An√°lise de Sentimentos dos Simpsons")
    
    if st.button("Testar Conex√£o com API"):
        if test_api_connection():
            st.success("Conex√£o com a API bem-sucedida!")
        else:
            st.error("Falha na conex√£o com a API. Verifique os logs para mais detalhes.")
    
    if not st.session_state.analysis_done:
        if st.button("Iniciar An√°lise de Sentimentos"):
            with st.spinner("Analisando sentimentos dos di√°logos dos Simpsons..."):
                progress_bar = st.progress(0)
                
                def update_progress(progress):
                    progress_bar.progress(progress)
                
                st.session_state.episode_lines, st.session_state.distribution, _, _, st.session_state.num_calls = analyze_simpsons_sentiments(update_progress)
                
                progress_bar.empty()
            
            st.session_state.analysis_done = True

    if st.session_state.analysis_done:
        st.success("An√°lise conclu√≠da!")
        st.subheader("N√∫mero de chamadas ao LLM")
        st.write(f"Foram necess√°rias {st.session_state.num_calls} chamadas ao LLM.")
        
        st.subheader("Distribui√ß√£o de Sentimentos")
        fig, ax = plt.subplots()
        st.session_state.distribution.plot(kind='bar', ax=ax)
        plt.title("Distribui√ß√£o de Sentimentos nas Falas")
        plt.xlabel("Sentimento")
        plt.ylabel("Propor√ß√£o")
        st.pyplot(fig)

        st.subheader("Exemplo de Falas Classificadas")
        if not st.session_state.episode_lines.empty and 'sentiment' in st.session_state.episode_lines.columns:
            sample_df = st.session_state.episode_lines[['spoken_words', 'sentiment']].dropna()
            if not sample_df.empty:
                sample_size = min(10, len(sample_df))
                sample = sample_df.sample(sample_size, random_state=42)
                st.dataframe(sample.style.set_properties(**{'text-align': 'left'}))
            else:
                st.write("N√£o h√° dados de sentimento dispon√≠veis ap√≥s a remo√ß√£o de valores nulos.")
        else:
            st.write("N√£o h√° dados de sentimento dispon√≠veis.")
        
        if st.button("Exportar Resultados para CSV"):
            csv_path = export_to_csv(st.session_state.episode_lines)
            st.success(f"Arquivo CSV salvo em: {csv_path}")
            
            with open(csv_path, "rb") as file:
                st.download_button(
                    label="Baixar arquivo CSV",
                    data=file,
                    file_name="simpsons_sentiment_analysis.csv",
                    mime="text/csv"
                )

with tab6:
    st.write("Chat com Ollama est√° temporariamente indispon√≠vel.")

with tab7:
    st.header("Resumo do Epis√≥dio dos Simpsons")
    
    if st.button("Testar Conex√£o com API", key="test_api_connection_button"):
        if test_api_connection():
            st.success("Conex√£o com a API bem-sucedida!")
        else:
            st.error("Falha na conex√£o com a API. Verifique os logs para mais detalhes.")
    
    if st.button("Analisar Epis√≥dio", key="analyze_episode_button"):
        with st.spinner("Gerando resumo do epis√≥dio... Isso pode levar alguns minutos."):
            summary, token_count = summarize_episode(92, 5)  # epis√≥dio 92 da temporada 5
        
        st.success("Resumo gerado com sucesso!")
        
        st.subheader(f"Resumo do Epis√≥dio 92 da Temporada 5")
        st.write(summary)
        st.write(f"N√∫mero de tokens no resumo: {token_count}")


with tab8:
    st.header("Resumo Detalhado do Epis√≥dio dos Simpsons")
    
    if st.button("Testar Conex√£o com API", key="test_api_connection_button_detailed"):
        if test_api_connection():
            st.success("Conex√£o com a API bem-sucedida!")
        else:
            st.error("Falha na conex√£o com a API. Verifique os logs para mais detalhes.")
    
    if st.button("Gerar Resumo Detalhado", key="analyze_episode_detailed_button"):
        with st.spinner("Gerando resumo detalhado do epis√≥dio... Isso pode levar alguns minutos."):
            final_summary, num_chunks, evaluation, chunk_summaries, chunk_evaluations = analyze_episode_summary(92, 5)
        
        st.success("An√°lise detalhada conclu√≠da!")
        
        st.subheader("Resumo Final do Epis√≥dio")
        st.write(final_summary)
        
        st.subheader("Detalhes da An√°lise")
        st.write(f"N√∫mero de chunks necess√°rios: {num_chunks}")
        
        st.subheader("Avalia√ß√£o do Resumo Final")
        st.write(evaluation)
        
        with st.expander("Ver Resumos e Avalia√ß√µes dos Chunks"):
            for i, (summary, eval) in enumerate(zip(chunk_summaries, chunk_evaluations)):
                st.subheader(f"Chunk {i+1}")
                st.write("Resumo:")
                st.write(summary)
                st.write("Avalia√ß√£o:")
                st.write(eval)

with tab9:
    st.header("Compara√ß√£o de M√©tricas dos Resumos")
    
    if st.button("Gerar Compara√ß√£o", key="compare_summaries_button"):
        with st.spinner("Gerando compara√ß√£o dos resumos... Isso pode levar alguns minutos."):
            final_summary, num_chunks, _, chunk_summaries, _, reference_summary = analyze_episode_summary(92, 5)
            
            final_metrics, chunk_metrics = compare_summaries(reference_summary, final_summary, chunk_summaries)
            convergence_analysis, omitted_info = analyze_convergence(reference_summary, final_summary, chunk_summaries)
        
        st.success("Compara√ß√£o conclu√≠da!")
        
        st.subheader("M√©tricas do Resumo Final")
        st.write(final_metrics)
        
        st.subheader("M√©tricas dos Chunks")
        for i, metrics in enumerate(chunk_metrics):
            st.write(f"Chunk {i+1}:")
            st.write(metrics)
        
        st.subheader("An√°lise de Converg√™ncia")
        st.write(convergence_analysis)
        
        st.subheader("Informa√ß√µes Omitidas")
        st.write(omitted_info)
        
        st.subheader("Resumos")
        st.write("Resumo de Refer√™ncia (Exerc√≠cio 7):")
        st.write(reference_summary)
        st.write("Resumo Final (Exerc√≠cio 8):")
        st.write(final_summary)

with tab10:
    export_sentiment_analysis() 



with tab11:
    sentiment_viz_main()


    
# # Barra lateral
# st.sidebar.header("Sobre")
# st.sidebar.info(
#     "Esta aplica√ß√£o realiza an√°lises de texto e dados, incluindo gera√ß√£o de texto, "
#     "categoriza√ß√£o de manchetes e an√°lise de epis√≥dios de The Simpsons. "
#     "Algumas funcionalidades est√£o temporariamente indispon√≠veis."
# )

# # Footer
# st.sidebar.markdown("---")
# st.sidebar.markdown("Desenvolvido com ‚ù§Ô∏è usando Streamlit")