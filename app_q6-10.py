import os
import streamlit as st
import requests
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
from collections import Counter
from dotenv import load_dotenv
import pandas as pd
import numpy as np
from openai import OpenAI

from simpsons_analysis import analyze_episode_summary, test_api_connection, analyze_episode
from summary_metrics import compare_summaries, analyze_convergence
from export import export_sentiment_analysis
from sentiment_visualization import main as sentiment_viz_main
from simpsons_sentiment_analysis import analyze_simpsons_sentiments, test_api_connection, export_to_csv
from sentiment_visualization import main as sentiment_viz_main

st.set_page_config(page_title="Gerador de Texto AI e Categoriza칞칚o de Manchetes", page_icon="游뱄", layout="wide")

load_dotenv()

# vari치veis de estado
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
if 'episode_lines' not in st.session_state:
    st.session_state.episode_lines = None
if 'distribution' not in st.session_state:
    st.session_state.distribution = None
if 'num_calls' not in st.session_state:
    st.session_state.num_calls = 0

# Configura o cliente nvidia
client = OpenAI(
    base_url=os.getenv("OPENAI_BASE_URL"),
    api_key=os.getenv("OPENAI_API_KEY")
)

def read_project_info():
    try:
        with open('project_info.txt', 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        return "Informa칞칫es do projeto n칚o encontradas."

# coletar manchetes
def get_headlines():
    url = "https://noticias.ufal.br/"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    headlines = [h.text.strip() for h in soup.find_all('a', class_='titulo')]
    return headlines

def create_chart(categorized):
    categories = [item['category'] for item in categorized]
    count = Counter(categories)
    
    fig, ax = plt.subplots()
    ax.bar(count.keys(), count.values())
    ax.set_title('Categoriza칞칚o das Manchetes da UFAL')
    ax.set_xlabel('Categorias')
    ax.set_ylabel('Quantidade de Manchetes')
    
    return fig, count

# Fun칞칚o para a aplica칞칚o de categoriza칞칚o de manchetes
def headline_categorization_app():
    st.header("Categoriza칞칚o de Manchetes da UFAL")
    st.write("A funcionalidade de categoriza칞칚o est치 temporariamente indispon칤vel.")
    
    if st.button("Coletar Manchetes"):
        with st.spinner("Coletando manchetes..."):
            headlines = get_headlines()
            st.subheader("Manchetes Coletadas:")
            for headline in headlines:
                st.write(headline)

# T칤tulo principal da aplica칞칚o
st.title("游뱄 Gerador de Texto AI e Categoriza칞칚o de Manchetes & 游뱄 An치lise de Texto e Dados")

# Abas principais
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10, tab11 = st.tabs([
    "Apresenta칞칚o", 
    "Gerador de Texto", 
    "Categoriza칞칚o de Manchetes", 
    "An치lise The Simpsons", 
    "An치lise de Sentimentos Simpsons",
    "Chat com Ollama",
    "Resumo do Epis칩dio",
    "Resumo Detalhado do Epis칩dio",
    "Compara칞칚o de M칠tricas",
    "Exportar An치lise de Sentimento",
    "Visualiza칞칚o de Sentimentos"
])

with tab1:
    project_info = read_project_info()
    st.markdown(project_info)

with tab2:
    st.write("Gerador de Texto AI est치 temporariamente indispon칤vel.")

with tab3:
    headline_categorization_app()

with tab4:
    st.write("An치lise The Simpsons est치 temporariamente indispon칤vel.")

# with tab5:
#     st.subheader("An치lise de Sentimentos dos Simpsons")
    
#     if st.button("Testar Conex칚o com API"):
#         if test_api_connection():
#             st.success("Conex칚o com a API bem-sucedida!")
#         else:
#             st.error("Falha na conex칚o com a API. Verifique os logs para mais detalhes.")
    
#     if st.button("Iniciar An치lise de Sentimentos"):
#         with st.spinner("Analisando sentimentos dos di치logos dos Simpsons..."):
#             progress_bar = st.progress(0)
            
#             def update_progress(progress):
#                 progress_bar.progress(progress)
            
#             episode_lines, distribution, accuracy, precision, num_calls = analyze_simpsons_sentiments(update_progress)
            
#             # remove a barra de progresso ap칩s a conclus칚o
#             progress_bar.empty()
        
#         st.success("An치lise conclu칤da!")
#         st.subheader("N칰mero de chamadas ao LLM")
#         st.write(f"Foram necess치rias {num_calls} chamadas ao LLM.")
#         st.subheader("Distribui칞칚o de Sentimentos")
#         fig, ax = plt.subplots()
#         distribution.plot(kind='bar', ax=ax)
#         plt.title("Distribui칞칚o de Sentimentos nas Falas")
#         plt.xlabel("Sentimento")
#         plt.ylabel("Propor칞칚o")
#         st.pyplot(fig)

#         st.subheader("Exemplo de Falas Classificadas")
#         if not episode_lines.empty and 'sentiment' in episode_lines.columns:
#             sample = episode_lines[['spoken_words', 'sentiment']].dropna().sample(10, random_state=42)
#             st.dataframe(sample.style.set_properties(**{'text-align': 'left'}))
#         else:
#             st.write("N칚o h치 dados de sentimento dispon칤veis.")


with tab5:
    st.subheader("An치lise de Sentimentos dos Simpsons")
    
    if st.button("Testar Conex칚o com API"):
        if test_api_connection():
            st.success("Conex칚o com a API bem-sucedida!")
        else:
            st.error("Falha na conex칚o com a API. Verifique os logs para mais detalhes.")
    
    if not st.session_state.analysis_done:
        if st.button("Iniciar An치lise de Sentimentos"):
            with st.spinner("Analisando sentimentos dos di치logos dos Simpsons..."):
                progress_bar = st.progress(0)
                
                def update_progress(progress):
                    progress_bar.progress(progress)
                
                st.session_state.episode_lines, st.session_state.distribution, _, _, st.session_state.num_calls = analyze_simpsons_sentiments(update_progress)
                
                progress_bar.empty()
            
            st.session_state.analysis_done = True

    if st.session_state.analysis_done:
        st.success("An치lise conclu칤da!")
        st.subheader("N칰mero de chamadas ao LLM")
        st.write(f"Foram necess치rias {st.session_state.num_calls} chamadas ao LLM.")
        
        st.subheader("Distribui칞칚o de Sentimentos")
        fig, ax = plt.subplots()
        st.session_state.distribution.plot(kind='bar', ax=ax)
        plt.title("Distribui칞칚o de Sentimentos nas Falas")
        plt.xlabel("Sentimento")
        plt.ylabel("Propor칞칚o")
        st.pyplot(fig)

        st.subheader("Exemplo de Falas Classificadas")
        if not st.session_state.episode_lines.empty and 'sentiment' in st.session_state.episode_lines.columns:
            sample_df = st.session_state.episode_lines[['spoken_words', 'sentiment']].dropna()
            if not sample_df.empty:
                sample_size = min(10, len(sample_df))
                sample = sample_df.sample(sample_size, random_state=42)
                st.dataframe(sample.style.set_properties(**{'text-align': 'left'}))
            else:
                st.write("N칚o h치 dados de sentimento dispon칤veis ap칩s a remo칞칚o de valores nulos.")
        else:
            st.write("N칚o h치 dados de sentimento dispon칤veis.")
        
        if st.button("Exportar Resultados para CSV"):
            csv_path = export_to_csv(st.session_state.episode_lines)
            st.success(f"Arquivo CSV salvo em: {csv_path}")
            
            with open(csv_path, "rb") as file:
                st.download_button(
                    label="Baixar arquivo CSV",
                    data=file,
                    file_name="simpsons_sentiment_analysis.csv",
                    mime="text/csv"
                )

with tab6:
    st.write("Chat com Ollama est치 temporariamente indispon칤vel.")

with tab7:
    st.header("Resumo do Epis칩dio dos Simpsons")
    
    if st.button("Testar Conex칚o com API", key="test_api_connection_button"):
        if test_api_connection():
            st.success("Conex칚o com a API bem-sucedida!")
        else:
            st.error("Falha na conex칚o com a API. Verifique os logs para mais detalhes.")
    
    if st.button("Analisar Epis칩dio", key="analyze_episode_button"):
        with st.spinner("Gerando resumo do epis칩dio... Isso pode levar alguns minutos."):
            summary, token_count = summarize_episode(92, 5)  # epis칩dio 92 da temporada 5
        
        st.success("Resumo gerado com sucesso!")
        
        st.subheader(f"Resumo do Epis칩dio 92 da Temporada 5")
        st.write(summary)
        st.write(f"N칰mero de tokens no resumo: {token_count}")


with tab8:
    st.header("Resumo Detalhado do Epis칩dio dos Simpsons")
    
    if st.button("Testar Conex칚o com API", key="test_api_connection_button_detailed"):
        if test_api_connection():
            st.success("Conex칚o com a API bem-sucedida!")
        else:
            st.error("Falha na conex칚o com a API. Verifique os logs para mais detalhes.")
    
    if st.button("Gerar Resumo Detalhado", key="analyze_episode_detailed_button"):
        with st.spinner("Gerando resumo detalhado do epis칩dio... Isso pode levar alguns minutos."):
            final_summary, num_chunks, evaluation, chunk_summaries, chunk_evaluations = analyze_episode_summary(92, 5)
        
        st.success("An치lise detalhada conclu칤da!")
        
        st.subheader("Resumo Final do Epis칩dio")
        st.write(final_summary)
        
        st.subheader("Detalhes da An치lise")
        st.write(f"N칰mero de chunks necess치rios: {num_chunks}")
        
        st.subheader("Avalia칞칚o do Resumo Final")
        st.write(evaluation)
        
        with st.expander("Ver Resumos e Avalia칞칫es dos Chunks"):
            for i, (summary, eval) in enumerate(zip(chunk_summaries, chunk_evaluations)):
                st.subheader(f"Chunk {i+1}")
                st.write("Resumo:")
                st.write(summary)
                st.write("Avalia칞칚o:")
                st.write(eval)

with tab9:
    st.header("Compara칞칚o de M칠tricas dos Resumos")
    
    if st.button("Gerar Compara칞칚o", key="compare_summaries_button"):
        with st.spinner("Gerando compara칞칚o dos resumos... Isso pode levar alguns minutos."):
            final_summary, num_chunks, _, chunk_summaries, _, reference_summary = analyze_episode_summary(92, 5)
            
            final_metrics, chunk_metrics = compare_summaries(reference_summary, final_summary, chunk_summaries)
            convergence_analysis, omitted_info = analyze_convergence(reference_summary, final_summary, chunk_summaries)
        
        st.success("Compara칞칚o conclu칤da!")
        
        st.subheader("M칠tricas do Resumo Final")
        st.write(final_metrics)
        
        st.subheader("M칠tricas dos Chunks")
        for i, metrics in enumerate(chunk_metrics):
            st.write(f"Chunk {i+1}:")
            st.write(metrics)
        
        st.subheader("An치lise de Converg칡ncia")
        st.write(convergence_analysis)
        
        st.subheader("Informa칞칫es Omitidas")
        st.write(omitted_info)
        
        st.subheader("Resumos")
        st.write("Resumo de Refer칡ncia (Exerc칤cio 7):")
        st.write(reference_summary)
        st.write("Resumo Final (Exerc칤cio 8):")
        st.write(final_summary)

with tab10:
    export_sentiment_analysis() 



with tab11:
    sentiment_viz_main()


    
# # Barra lateral
# st.sidebar.header("Sobre")
# st.sidebar.info(
#     "Esta aplica칞칚o realiza an치lises de texto e dados, incluindo gera칞칚o de texto, "
#     "categoriza칞칚o de manchetes e an치lise de epis칩dios de The Simpsons. "
#     "Algumas funcionalidades est칚o temporariamente indispon칤veis."
# )

# # Footer
# st.sidebar.markdown("---")
# st.sidebar.markdown("Desenvolvido com 仇벒잺 usando Streamlit")